# -*- coding: utf-8 -*-
"""style-transfer-web.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kGz7uksEECBQtDWq6gbiPIG5k15RhET-
"""

#import packages
import tensorflow as tf
from tqdm import tqdm
import numpy as np
import PIL.Image

#create directory to save output images
!rm -rf outputs
!mkdir outputs

#image helper functions
def load_img(path_to_img):
  max_dim=500
  img = tf.io.read_file(path_to_img)
  img = tf.image.decode_image(img, channels=3)
  img = tf.image.convert_image_dtype(img, tf.float32)

  shape = tf.cast(tf.shape(img)[:-1], tf.float32)
  scale = max_dim / max(shape)
  new_shape = tf.cast(shape * scale, tf.int32)

  img = tf.image.resize(img, new_shape)
  img = img[tf.newaxis, :]
  return img

def tensor_to_image(tensor):
  tensor = tensor*255
  tensor = np.array(tensor, dtype=np.uint8)
  if np.ndim(tensor) > 3:
    assert tensor.shape[0] == 1
    tensor = tensor[0]
  return PIL.Image.fromarray(tensor)

#download images
style1_url = "https://upload.wikimedia.org/wikipedia/commons/thumb/e/ea/Van_Gogh_-_Starry_Night_-_Google_Art_Project.jpg/1024px-Van_Gogh_-_Starry_Night_-_Google_Art_Project.jpg"
style2_url = "https://i.etsystatic.com/13726973/r/il/aa6b47/2315742307/il_570xN.2315742307_toeh.jpg"
style3_url="https://i.pinimg.com/564x/90/f9/81/90f981091321ea4a91b27b04c84f37f1.jpg"

content1_url = "https://images.unsplash.com/photo-1536703965899-85f65f163d58?ixid=MXwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHw%3D&ixlib=rb-1.2.1&auto=format&fit=crop&w=1051&q=80"
content2_url = "https://images.unsplash.com/photo-1505245208761-ba872912fac0?ixid=MXwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHw%3D&ixlib=rb-1.2.1&auto=format&fit=crop&w=1050&q=80"

style1_path = tf.keras.utils.get_file('style1.jpg', style1_url)
style2_path = tf.keras.utils.get_file('style2.jpg', style2_url)
style3_path = tf.keras.utils.get_file('style3.jpg', style3_url)
content1_path = tf.keras.utils.get_file('content1.jpg', content1_url)
content2_path = tf.keras.utils.get_file('content2.jpg', content2_url)

#load and show images
style_imgs = [load_img(style1_path), load_img(style2_path),load_img(style3_path)]
content_imgs = [load_img(content1_path), load_img(content2_path)]
display(tensor_to_image(style_imgs[0]))
display(tensor_to_image(style_imgs[1]))
display(tensor_to_image(content_imgs[0]))display(tensor_to_image(style_imgs[0]))
display(tensor_to_image(content_imgs[1]))

#load vgg
vgg=tf.keras.applications.VGG19(include_top=False, weights='imagenet')
vgg.trainable=False

#define layers
equal_style_weights = {'block1_conv1':1,
                       'block2_conv1':1,
                       'block3_conv1':1, 
                       'block4_conv1':1, 
                       'block5_conv1':1}
style_layers = [*equal_style_weights.keys()]
content_layer = 'block4_conv2'

#define loss function
def get_features(image, layers):
  outputs=[vgg.get_layer(layer).output for layer in layers]
  #build model using given layers
  model_vgg=tf.keras.Model(inputs=[vgg.input],outputs=outputs)
  input=tf.keras.applications.vgg19.preprocess_input(image*255.0)
  output_layers=model_vgg(input)
  features={}
  for i in range(len(layers)):
    features[layers[i]] = output_layers[i]
  return features

def gram_matrix(tensor):
  result = tf.linalg.einsum('bijc,bijd->bcd', tensor, tensor)
  input_shape = tf.shape(tensor)
  num_locations = tf.cast(input_shape[1]*input_shape[2], tf.float32)
  return result/(num_locations)
  

def total_loss(target, style_weight, content_weight, style_weights, style_grams, content_features): 
  target_features = get_features(target, [*style_weights.keys(), content_layer])

  content_loss = tf.reduce_mean((target_features[content_layer] - content_features[content_layer]) ** 2)

  style_loss = 0
  # iterate through each style layer and add to the style loss
  for layer in style_layers:
    target_feature = target_features[layer]
    target_gram = gram_matrix(target_feature)
    # target_gram = target_features['style'][layer]
    style_gram = style_grams[layer]
    layer_style_loss = tf.reduce_mean((target_gram - style_gram) ** 2)
    style_loss += style_weights[layer] * layer_style_loss

  total_loss=style_weight * style_loss / sum(style_weights.values())  + content_weight * content_loss
  return (total_loss)

#define the function to actually do the style transfer
def style_transfer(style_img, content_img, style_weight, content_weight, steps, style_weights=None, target=None, seed=100, variation_weight=0):
  if style_weights is None:
    style_weights = equal_style_weights
  if target is None:
    #initialize with white noise 
    shape = content_img.shape
    rand_vals = [tf.random.uniform([shape[1], shape[2]], seed=seed)] * 3
    rand_vals = tf.transpose(rand_vals, [1, 2, 0])
    rand_vals = tf.reshape(rand_vals, shape)
    target = tf.Variable(rand_vals)
    # target = tf.Variable(content_img)
  optimizer = tf.optimizers.Adam(learning_rate=0.1, beta_1=0.99, epsilon=1e-1)
  style_features=get_features(style_img, style_layers)
  content_features = get_features(content_img, [content_layer])
  style_grams = {layer: gram_matrix(style_features[layer]) for layer in style_features}

  for i in tqdm(range(steps)):
    with tf.GradientTape() as tape:
      loss = total_loss(target, style_weight, content_weight, style_weights, style_grams, content_features)
      if variation_weight > 0:
        loss += variation_weight * tf.image.total_variation(target)
      grad = tape.gradient(loss, target)
    optimizer.apply_gradients([(grad, target)])
    target.assign(tf.clip_by_value(target, clip_value_min=.0, clip_value_max=1.0))
  return target

"""**Application**"""

#default parameters
style_weight = 1
content_weight = 5e2
n_iterations = 10000

#test
target = style_transfer(style_imgs[0], content_imgs[0], style_weight, content_weight, n_iterations)
image = tensor_to_image(target)
display(image)

"""**different pairs**"""

#different pairs
for style in range(2):
  for content in range(2):
    target = style_transfer(style_imgs[style], content_imgs[content], style_weight, content_weight, n_iterations)
    image = tensor_to_image(target)
    display(image)
    image.save(f'outputs/pair-{style+1}-{content+1}.jpg')

"""number of iterations"""

#number of iterations
target = None
for iter in [2500, 5000, 7500, 10000]:
  target = style_transfer(style_imgs[0], content_imgs[0], style_weight, content_weight, iter)
  image = tensor_to_image(target)
  display(image)
  image.save(f'outputs/iter-{iter}.jpg')

"""**different weight ratio** """

#content style weight ratio
target = None
for i in [0, 1, 3, 4]:
  target = style_transfer(style_imgs[0], content_imgs[0], 1, 10 ** i, n_iterations)
  image = tensor_to_image(target)
  display(image)
  image.save(f'outputs/ratio-10-{i}.jpg')

"""different initialization"""

#different initialization with content image
target = tf.Variable(content_imgs[0])
target = style_transfer(style_imgs[0], content_imgs[0], style_weight, content_weight, n_iterations, target=target)
image = tensor_to_image(target)
display(image)
image.save(f'outputs/init-content.jpg')

#different initialization with different seed
target = style_transfer(style_imgs[0], content_imgs[0], style_weight, content_weight, n_iterations, seed=278432)
image = tensor_to_image(target)
display(image)
image.save(f'outputs/init-seed-1.jpg')

"""different style weights"""

#different style weights
diff_style_weights = {'block1_conv1':1,
                      'block2_conv1':0.8,
                      'block3_conv1':0.6, 
                      'block4_conv1':0.4, 
                      'block5_conv1':0.2}

target = style_transfer(style_imgs[0], content_imgs[0], style_weight, content_weight, n_iterations, style_weights=diff_style_weights)
image = tensor_to_image(target)
display(image)
image.save(f'outputs/styleweights-1.jpg')

"""adding variation loss"""

# for style in range(2):
#   for content in range(2):
target=style_transfer(style_imgs[0], content_imgs[0], style_weight, content_weight, n_iterations, variation_weight=30)
image = tensor_to_image(target)
display(image)
image.save(f'outputs/varloss.jpg')

"""style transfer with photo"""

display(tensor_to_image(content_imgs[1]))
display(tensor_to_image(style_imgs[2]))

target = style_transfer(style_imgs[2], content_imgs[1], style_weight, content_weight,n_iterations,diff_style_weights, variation_weight=30)
image = tensor_to_image(target)
display(image)
image.save(f'outputs/photo.jpg')